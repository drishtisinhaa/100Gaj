{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181e8aed-3912-4fa3-87e4-1ee8efb23d6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca57e54-fcf1-4b83-be49-a2beecb1e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('real_estate_delhi_ncr_arranged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61f8ccc-9b81-4466-9027-8725216c8320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>SubLocation</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rate_per_sqft</th>\n",
       "      <th>Bedroom</th>\n",
       "      <th>Status</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Carpet_area_sqft</th>\n",
       "      <th>Total_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>AG1 Pocket Vikaspuri</td>\n",
       "      <td>2 BHK Flat for Sale in AG1 Pocket Vikaspuri, V...</td>\n",
       "      <td>12500000</td>\n",
       "      <td>13228.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>New Property</td>\n",
       "      <td>NaN</td>\n",
       "      <td>944.965225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Aastha Kunj Apartments</td>\n",
       "      <td>3 BHK Flat for Sale in Aastha Kunj Apartments,...</td>\n",
       "      <td>13000000</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>New Property</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1745.200698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Adarsh Apartment</td>\n",
       "      <td>2 BHK Flat for Sale in Adarsh Apartment, Rohin...</td>\n",
       "      <td>17000000</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>2732.240437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Adarsh Nagar Extension</td>\n",
       "      <td>2 BHK Flat for Sale in Adarsh Nagar Extension,...</td>\n",
       "      <td>10500000</td>\n",
       "      <td>11667.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>525.0</td>\n",
       "      <td>899.974286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Aditi Apartment</td>\n",
       "      <td>3 BHK Flat for Sale in Aditi Apartment, Indrap...</td>\n",
       "      <td>17500000</td>\n",
       "      <td>10606.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650.009429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>Faridabad</td>\n",
       "      <td>Tirka Colony</td>\n",
       "      <td>3 BHK House for Sale in Tirka Colony, Mathura ...</td>\n",
       "      <td>4800000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>Faridabad</td>\n",
       "      <td>Urban One</td>\n",
       "      <td>2 BHK Flat for Sale in Urban One, Dayal Bagh C...</td>\n",
       "      <td>3000000</td>\n",
       "      <td>6422.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>750.0</td>\n",
       "      <td>467.144192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>Faridabad</td>\n",
       "      <td>Woodbury Tower</td>\n",
       "      <td>3 BHK Flat for Sale in Woodbury Tower, Suraj K...</td>\n",
       "      <td>12500000</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>1635.055592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>Faridabad</td>\n",
       "      <td>sai park Apartment sector 87</td>\n",
       "      <td>2 BHK Flat for Sale in sai park Apartment sect...</td>\n",
       "      <td>4600000</td>\n",
       "      <td>4875.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>943.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>Faridabad</td>\n",
       "      <td>sector 10 HBC Faridabad</td>\n",
       "      <td>3 BHK House for Sale in sector 10 HBC Faridabad</td>\n",
       "      <td>4500000</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ready to Move</td>\n",
       "      <td>Resale</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City                   SubLocation  \\\n",
       "0         Delhi          AG1 Pocket Vikaspuri   \n",
       "1         Delhi        Aastha Kunj Apartments   \n",
       "2         Delhi              Adarsh Apartment   \n",
       "3         Delhi        Adarsh Nagar Extension   \n",
       "4         Delhi               Aditi Apartment   \n",
       "...         ...                           ...   \n",
       "2340  Faridabad                  Tirka Colony   \n",
       "2341  Faridabad                     Urban One   \n",
       "2342  Faridabad                Woodbury Tower   \n",
       "2343  Faridabad  sai park Apartment sector 87   \n",
       "2344  Faridabad       sector 10 HBC Faridabad   \n",
       "\n",
       "                                                   Name     Price  \\\n",
       "0     2 BHK Flat for Sale in AG1 Pocket Vikaspuri, V...  12500000   \n",
       "1     3 BHK Flat for Sale in Aastha Kunj Apartments,...  13000000   \n",
       "2     2 BHK Flat for Sale in Adarsh Apartment, Rohin...  17000000   \n",
       "3     2 BHK Flat for Sale in Adarsh Nagar Extension,...  10500000   \n",
       "4     3 BHK Flat for Sale in Aditi Apartment, Indrap...  17500000   \n",
       "...                                                 ...       ...   \n",
       "2340  3 BHK House for Sale in Tirka Colony, Mathura ...   4800000   \n",
       "2341  2 BHK Flat for Sale in Urban One, Dayal Bagh C...   3000000   \n",
       "2342  3 BHK Flat for Sale in Woodbury Tower, Suraj K...  12500000   \n",
       "2343  2 BHK Flat for Sale in sai park Apartment sect...   4600000   \n",
       "2344    3 BHK House for Sale in sector 10 HBC Faridabad   4500000   \n",
       "\n",
       "      Rate_per_sqft  Bedroom         Status   Transaction  Carpet_area_sqft  \\\n",
       "0           13228.0        2  Ready to Move  New Property               NaN   \n",
       "1            7449.0        3  Ready to Move  New Property            2600.0   \n",
       "2            6222.0        2  Ready to Move        Resale            2620.0   \n",
       "3           11667.0        2  Ready to Move        Resale             525.0   \n",
       "4           10606.0        3  Ready to Move        Resale               NaN   \n",
       "...             ...      ...            ...           ...               ...   \n",
       "2340        10000.0        3  Ready to Move        Resale               NaN   \n",
       "2341         6422.0        2  Ready to Move        Resale             750.0   \n",
       "2342         7645.0        3  Ready to Move        Resale            1150.0   \n",
       "2343         4875.0        2  Ready to Move        Resale               NaN   \n",
       "2344        12500.0        3  Ready to Move        Resale            2150.0   \n",
       "\n",
       "       Total_area  \n",
       "0      944.965225  \n",
       "1     1745.200698  \n",
       "2     2732.240437  \n",
       "3      899.974286  \n",
       "4     1650.009429  \n",
       "...           ...  \n",
       "2340   480.000000  \n",
       "2341   467.144192  \n",
       "2342  1635.055592  \n",
       "2343   943.589744  \n",
       "2344   360.000000  \n",
       "\n",
       "[2345 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14eeb1c-17e3-4100-8f20-602ff8ce2311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac5eb40-baf2-40b3-9bf7-148699de0fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14343a9e-f4bf-4426-8c92-223dd730b8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   0\n",
       "SubLocation            0\n",
       "Name                   0\n",
       "Price                  0\n",
       "Rate_per_sqft         88\n",
       "Bedroom                0\n",
       "Status               128\n",
       "Transaction            1\n",
       "Carpet_area_sqft    1147\n",
       "Total_area            88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a91542e-9612-42e7-a280-a2d8eabece6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the carpet_are_sqft\n",
    "df.drop('Carpet_area_sqft',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db32a24d-d05a-498d-a543-2fa4860f507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction\n",
       "Resale          1873\n",
       "New Property     467\n",
       "Other              4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Transaction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e425c4-9980-4d3e-a2cc-f07785318705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.Transaction=='Resale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd0e970-3b4e-43f9-9e7f-ec4f7a7cbf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City               0\n",
       "SubLocation        0\n",
       "Name               0\n",
       "Price              0\n",
       "Rate_per_sqft     72\n",
       "Bedroom            0\n",
       "Status           102\n",
       "Transaction        0\n",
       "Total_area        72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a761aa1-9544-46f2-85fe-53ab31eb5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Resale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2813f155-cfad-46ce-937b-a9542879f42a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"ðŸš€ Starting model training...\")\n",
    "\n",
    "# Load dataset and clean column names\n",
    "df = pd.read_csv(\"real_estate_delhi_ncr_arranged.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "print(f\"ðŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"ðŸ“‹ Columns: {list(df.columns)}\")\n",
    "\n",
    "# Drop missing targets\n",
    "df.dropna(subset=[\"price\"], inplace=True)\n",
    "df.drop(columns=[\"unnamed: 0\"], errors='ignore', inplace=True)\n",
    "\n",
    "print(f\"ðŸ“Š After cleaning: {df.shape}\")\n",
    "\n",
    "# Log transform target\n",
    "df[\"price\"] = np.log1p(df[\"price\"])\n",
    "\n",
    "# Feature Engineering\n",
    "if \"bhk\" in df.columns and \"total_area\" in df.columns:\n",
    "    df[\"bhk_per_1000sqft\"] = df[\"bhk\"] / (df[\"total_area\"] / 1000 + 1)\n",
    "    df[\"price_per_bhk\"] = np.expm1(df[\"price\"]) / (df[\"bhk\"] + 1)\n",
    "\n",
    "# Remove outliers\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "z_scores = np.abs((numeric_df - numeric_df.mean()) / numeric_df.std())\n",
    "df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "print(f\"ðŸ“Š After outlier removal: {df.shape}\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Handle skewed numerical features\n",
    "skewed_cols = [\"total_area\", \"rate_per_sqft\", \"carpet_area_sqft\"]\n",
    "for col in skewed_cols:\n",
    "    if col in X.columns:\n",
    "        X[col] = np.log1p(X[col])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"ðŸ”¢ Numerical columns: {num_cols}\")\n",
    "print(f\"ðŸ“ Categorical columns: {cat_cols}\")\n",
    "\n",
    "# Preprocessing\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# Transform features\n",
    "print(\"ðŸ”„ Transforming features...\")\n",
    "X_train_t = preprocessor.fit_transform(X_train)\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"âœ… Transformed feature shape: {X_train_t.shape}\")\n",
    "\n",
    "# Base models - Fixed XGBoost parameters\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=4,\n",
    "    subsample=0.7, \n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.5, \n",
    "    reg_lambda=1.0,\n",
    "    random_state=42, \n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    device='cpu'  # Fixed: using device instead of predictor\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Stacking Regressor\n",
    "stack_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb), ('rf', rf)],\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "print(\"ðŸ‹ï¸ Training stacked model...\")\n",
    "stack_model.fit(X_train_t, y_train)\n",
    "\n",
    "# Predict\n",
    "print(\"ðŸ”® Making predictions...\")\n",
    "y_train_pred = np.expm1(stack_model.predict(X_train_t))\n",
    "y_test_pred = np.expm1(stack_model.predict(X_test_t))\n",
    "\n",
    "# Evaluate\n",
    "def evaluate(y_true, y_pred, label):\n",
    "    y_true_exp = np.expm1(y_true)\n",
    "    print(f\"\\nðŸ” {label}\")\n",
    "    print(f\"R2 Score: {r2_score(y_true_exp, y_pred):.4f}\")\n",
    "    print(f\"RMSE: â‚¹{np.sqrt(mean_squared_error(y_true_exp, y_pred)):,.2f}\")\n",
    "    print(f\"MAE: â‚¹{mean_absolute_error(y_true_exp, y_pred):,.2f}\")\n",
    "\n",
    "evaluate(y_train, y_train_pred, \"Train Set - Stacked Model\")\n",
    "evaluate(y_test, y_test_pred, \"Test Set - Stacked Model\")\n",
    "\n",
    "# Save the complete pipeline\n",
    "print(\"\\nðŸ’¾ Saving model and preprocessor...\")\n",
    "\n",
    "# Save the model\n",
    "with open('model1.pkl', 'wb') as f:\n",
    "    pickle.dump(stack_model, f)\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Save feature information\n",
    "feature_info = {\n",
    "    'num_cols': num_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'feature_names': list(X.columns),\n",
    "    'target_transformed': True,  # Target was log-transformed\n",
    "    'skewed_cols_transformed': skewed_cols\n",
    "}\n",
    "\n",
    "with open('feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "\n",
    "# Create a simple model for API testing (fallback)\n",
    "print(\"\\nðŸŽ¯ Creating simple model for API...\")\n",
    "\n",
    "# Create a simple dataset for API testing\n",
    "api_data = pd.DataFrame({\n",
    "    'purchase_price': [5000000, 3000000, 8000000, 4500000, 6000000],\n",
    "    'monthly_rent': [35000, 25000, 55000, 32000, 42000],\n",
    "    'renovation_cost': [200000, 150000, 300000, 180000, 250000]\n",
    "})\n",
    "\n",
    "# Create realistic resale values\n",
    "api_data['resale_value'] = (\n",
    "    api_data['purchase_price'] * 1.4 +  # 40% appreciation over 5 years\n",
    "    api_data['renovation_cost'] * 0.6 +  # 60% of renovation cost retained\n",
    "    api_data['monthly_rent'] * 12 * 2   # 2 years of rent as bonus\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_simple = api_data[['purchase_price', 'monthly_rent', 'renovation_cost']]\n",
    "y_simple = api_data['resale_value']\n",
    "\n",
    "scaler_simple = StandardScaler()\n",
    "X_simple_scaled = scaler_simple.fit_transform(X_simple)\n",
    "\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_simple_scaled, y_simple)\n",
    "\n",
    "# Wrapper class for simple model\n",
    "class SimpleRealEstateModel:\n",
    "    def __init__(self, model, scaler):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, list):\n",
    "            X = np.array(X).reshape(1, -1)\n",
    "        elif len(X.shape) == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "simple_model = SimpleRealEstateModel(model_simple, scaler_simple)\n",
    "\n",
    "# Save simple model as backup\n",
    "with open('simple_model.pkl', 'wb') as f:\n",
    "    pickle.dump(simple_model, f)\n",
    "\n",
    "print(\"âœ… All models saved successfully!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- model1.pkl (Stacked model)\")\n",
    "print(\"- preprocessor.pkl (Data preprocessor)\")\n",
    "print(\"- feature_info.pkl (Feature metadata)\")\n",
    "print(\"- simple_model.pkl (Simple model for API testing)\")\n",
    "\n",
    "# Test the simple model\n",
    "test_input = np.array([[5000000, 40000, 200000]])\n",
    "prediction = simple_model.predict(test_input)\n",
    "print(f\"\\nðŸ§ª Simple model test: â‚¹{prediction[0]:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
